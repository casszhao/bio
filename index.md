---
layout: default
---

## About Me

<img class="profile-picture" src="avatar.jpg">

I am Cass (Zhixue) Zhao, a lecturer in [Natural Language Processing](https://www.sheffield.ac.uk/dcs/research/groups/natural-language-processing) at the Computer Science Department of the University of Sheffield. Before that, I was a Postdoc researcher, supervised by [Prof. Nikos Aletras](https://nikosaletras.com/), on model interpretability, model hallucination, and model compression. Back in 2020, I worked as a research assistant within the same department, working on NIHR-funded NLP projects for systematic reviews of public health research. My Ph.D. research applied transfer learning to hate speech detection tasks and investigated model bias, which was funded by the University of Sheffield.

I've served in the Program Committee for AAAI, ACL, NAACL and EMNLP. I serve as a reviewer for ACL ARR.

<font color=White>Test</font>
<font color=White>Test</font>

I am looking for highly motivated PhD students. 

**A fully funded PhD studentship (3.5 years) is available. Contact me if interested.**

<font color=White>Test</font>
<font color=White>Test</font>

## Research Interest

Trustworthy AI, Model explanations, Generative models, Hallucination, Faithfulness, Text generation



<font color=White>Test</font>
<font color=White>Test</font>

## Recent Publications

Zhao, Z., N. Aletras (2024). Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models. 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics.
[[NAACL 2024 Main](https://arxiv.org/pdf/2403.12809.pdf)]


Zhao, Z., N. Aletras (2023). Incorporating Attribution Importance for Improving Faithfulness Metrics. The 61st Annual Meeting of the Association for Computational Linguistics.
[[ACL 2023 Main](https://aclanthology.org/2023.acl-long.261/)]
[[Oral Presentation](https://us06web.zoom.us/rec/play/TisLvdRrfqNRYts4y0A6wJeoV2H6kL2eRywX7Jl_wGUxBVO_n_HoIfVi1lhO0OK1sUw-gDjFpHuuDz6o.-zDGXXlaq7nOwrW7?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2Fc0BepePE3QACrdQQpFnEISDmrUSvV5T7XwJcW1TN0jkGEvVMutm55KeLx9eKWXH4.R0SYaV552qVO0sfV)] (the 1st talk was ours)


Zhao, Z., G. Chrysostomou, K. Bontcheva and N. Aletras (2022). On the Impact of Temporal Concept Drift on Model Explanations. In Findings of the Association for Computational Linguistics [[EMNLP 2022 Findings](https://aclanthology.org/2022.findings-emnlp.298/)]


Zhao, Z., Zhang, Z., Hopfgartner, F. (2022). Utilizing Subjectivity Level to Mitigate Identity Term Bias in Toxic Comments Classification. Online Social Networks and Media, 29, 100205. [[Journal](https://www.sciencedirect.com/science/article/abs/pii/S246869642200009X)]


Zhao, Z., Zhang, Z., Hopfgartner, F. (2021). A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification. In Companion Proceedings of the Web Conference 2021 (pp. 500-507) [[WWW 2021](https://dl.acm.org/doi/abs/10.1145/3442442.3452313#:~:text=Our%20results%20show%20that%2C%20Out,such%20as%20CNN%20and%20BiLSTM.)]


(More papers in [publications](https://casszhao.github.io/cass/publications).)


<font color=White>Test</font>
<font color=White>Test</font>


<font color=White>Test</font>
## Extra
- Staff well-being Officer, Department of Computer Science, The University of Sheffield
- Communications Officer of [Staff Race Equality Network](https://staff.sheffield.ac.uk/staff-race-equality-network), The University of Sheffield
