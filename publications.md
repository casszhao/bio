---
layout: default
is_contact: true
---



## Publications

Zhao, Z., K. Bontcheva and N. Aletras (2022). Synergizing Importance Degrees on Evaluating Feature Attribution. Association for Computational Linguistics, ACL 2023. (submitted).

Zhao, Z., G. Chrysostomou, K. Bontcheva and N. Aletras (2022). On the Impact of Temporal Concept Drift on Model Explanations. In Findings of the Association for Computational Linguistics: EMNLP 2022. [paper](https://aclanthology.org/2022.findings-emnlp.298/)

Clowes, M., Stansfield, C., Thomas, J., Shemilt, I., Paisley, S., Stevenson, M., Zhao, Z., Marshall, I., Kell, G., (June 2022). All is FAIR in health inequalities research: using machine learning to build a new database of health equity studies. European Association for Health Information and Libraries 2022. [project](https://eppi.ioe.ac.uk/eppi-vis/Fair)

Zhao, Z., Zhang, Z., Hopfgartner, F. (2022). Utilizing Subjectivity Level to Mitigate Identity Term Bias in Toxic Comments Classification. Online Social Networks and Media, 29, 100205. [paper](https://www.sciencedirect.com/science/article/abs/pii/S246869642200009X)

Zhao, Z., Zhang, Z., Hopfgartner, F. (2021). A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification. In Companion Proceedings of the Web Conference 2021 (pp. 500-507) [paper](https://dl.acm.org/doi/abs/10.1145/3442442.3452313#:~:text=Our%20results%20show%20that%2C%20Out,such%20as%20CNN%20and%20BiLSTM.)

Zhao, Z., Zhang, Z., Hopfgartner, F. (2019). Detecting Toxic Content Online and the Effect of Training Data on Classification Performance. In Proceedings of 20th International Conference on Computational Linguistics and Intelligent Text Processing, La Rochelle, France [paper](https://easychair.org/publications/preprint/XGmR)

