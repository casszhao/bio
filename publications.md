---
layout: default
is_contact: true
---



## Publications

George Chrysostomou, **<span style="color:grey">Zhixue Zhao</span>**, Miles Williams, and Nikolaos Aletras. 2024. Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization. 2024 Transactions of the Association for
Computational Linguistics. [TACL Vol. 12 (2024)](https://transacl.org/index.php/tacl/article/view/6271)

**<span style="color:grey">Zhixue Zhao</span>**, James Thomas, Gregory Kell, Claire Stansfield, Mark Clowes, Sergio Graziosi, Jeff Brunton, Iain James Marshall, Mark Stevenson. The FAIR database: facilitating access to public health
research literature. [JAMIA Vol.7 4(2024)](https://doi.org/10.1093/jamiaopen/ooae139)

**<span style="color:grey">Zhixue Zhao</span>** and Nikolaos Aletras. 2024. Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models. 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics. [NAACL 2024 Main](https://arxiv.org/pdf/2403.12809) (oral presentation)


**<span style="color:grey">Zhixue Zhao</span>** and Nikolaos Aletras. 2023. Incorporating Attribution Importance for Improving Faithfulness Metrics. The 61st Annual Meeting of the Association for Computational Linguistics.
[ACL 2023 Main](https://aclanthology.org/2023.acl-long.261/)
[[Oral Presentation](https://us06web.zoom.us/rec/play/TisLvdRrfqNRYts4y0A6wJeoV2H6kL2eRywX7Jl_wGUxBVO_n_HoIfVi1lhO0OK1sUw-gDjFpHuuDz6o.-zDGXXlaq7nOwrW7?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2Fc0BepePE3QACrdQQpFnEISDmrUSvV5T7XwJcW1TN0jkGEvVMutm55KeLx9eKWXH4.R0SYaV552qVO0sfV)] (the 1st talk was ours)

**<span style="color:grey">Zhixue Zhao</span>** and Boxuan Shan. 2024. ReAGent: A Model-agnostic Feature Attribution Method for Generative Language Models. [[ReLM@AAAI24](https://arxiv.org/pdf/2402.00794)] Use ReAGent via [Inseq](https://inseq.org/en/latest/main_classes/feature_attribution.html#inseq.attr.feat.ReagentAttribution)


**<span style="color:grey">Zhixue Zhao</span>**, George Chrysostomou, Kalina Bontcheva, and Nikolaos Aletras. 2022. On the Impact of Temporal Concept Drift on Model Explanations. In Findings of the Association for Computational Linguistics [EMNLP 2022 Findings](https://aclanthology.org/2022.findings-emnlp.298/)


**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, and Frank Hopfgartner. 2022. Utilizing Subjectivity Level to Mitigate Identity Term Bias in Toxic Comments Classification. Online Social Networks and Media, 29, 100205. [Journal](https://www.sciencedirect.com/science/article/abs/pii/S246869642200009X)


**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, and Frank Hopfgartner. 2021. A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification. In Companion Proceedings of the Web Conference 2021 (pp. 500-507) [WWW 2021](https://dl.acm.org/doi/abs/10.1145/3442442.3452313#:~:text=Our%20results%20show%20that%2C%20Out,such%20as%20CNN%20and%20BiLSTM.)

**<span style="color:grey">Zhixue Zhao</span>**, Ziqi Zhang, and Frank Hopfgartner. 2019. Detecting Toxic Content Online and the Effect of Training Data on Classification Performance. In Proceedings of 20th International Conference on Computational Linguistics and Intelligent Text Processing, La Rochelle, France [CICLing 2019](https://easychair.org/publications/preprint/XGmR)

